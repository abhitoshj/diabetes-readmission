{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28e81a15-fec8-4df1-a6b1-5bcefb343a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "## Added on 2024-11-14\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Added on 2024-11-15\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b04aca3-66b1-45cb-a32b-3ae46fbdf449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Definition of paths\\ndata_dir = os.path.join(os.getcwd(), '../Backup_Dataset')\\nprint(data_dir)\\n\\nraw_data_dir = os.path.join(data_dir, 'raw')\\nids_mapping = os.path.join(raw_data_dir, 'IDS_mapping.csv')\\ndiabetes_data = os.path.join(raw_data_dir, 'diabetic_data.csv')\\n\\nmapping_data_dir = os.path.join(data_dir, 'Mapping')\\nos.makedirs(mapping_data_dir, exist_ok=True)\\n\\npreprocessed_out_dir = os.path.join(data_dir, 'Preprocessed')\\nos.makedirs(preprocessed_out_dir, exist_ok=True)\\n\\nadmission_type_mapping_data = os.path.join(mapping_data_dir, 'admission_type_mapping.csv')\\ndischarge_disposition_data = os.path.join(mapping_data_dir, 'discharge_disposition_mapping.csv')\\nadmission_source_mapping_data = os.path.join(mapping_data_dir, 'admission_source_mapping.csv')\\n\\npreprocessed_saved_filepath = os.path.join(preprocessed_out_dir, 'preprocessed.pkl')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Definition of paths\n",
    "data_dir = os.path.join(os.getcwd(), '../Backup_Dataset')\n",
    "print(data_dir)\n",
    "\n",
    "raw_data_dir = os.path.join(data_dir, 'raw')\n",
    "ids_mapping = os.path.join(raw_data_dir, 'IDS_mapping.csv')\n",
    "diabetes_data = os.path.join(raw_data_dir, 'diabetic_data.csv')\n",
    "\n",
    "mapping_data_dir = os.path.join(data_dir, 'Mapping')\n",
    "os.makedirs(mapping_data_dir, exist_ok=True)\n",
    "\n",
    "preprocessed_out_dir = os.path.join(data_dir, 'Preprocessed')\n",
    "os.makedirs(preprocessed_out_dir, exist_ok=True)\n",
    "\n",
    "admission_type_mapping_data = os.path.join(mapping_data_dir, 'admission_type_mapping.csv')\n",
    "discharge_disposition_data = os.path.join(mapping_data_dir, 'discharge_disposition_mapping.csv')\n",
    "admission_source_mapping_data = os.path.join(mapping_data_dir, 'admission_source_mapping.csv')\n",
    "\n",
    "preprocessed_saved_filepath = os.path.join(preprocessed_out_dir, 'preprocessed.pkl')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34836597-f050-4f05-b05b-f3c309867b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist: C:\\Users\\amitniti\\OneDrive - Intel Corporation\\Documents\\AJ-Personal\\(INTEL) IISc-MTech\\2-Data Science in Practice\\Project-1-DSiP-DiabetesReadmit\\ANJ_GITclone\\2024-11-20\\Backup_Dataset\\Preprocessed\\preprocessed.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define the base directory using the current working directory\n",
    "current_dir = os.getcwd()\n",
    "backup_dir = os.path.join(current_dir, 'Backup_Dataset', 'Preprocessed')\n",
    "\n",
    "# File paths for both PKL files\n",
    "preprocessed_filepath = os.path.join(backup_dir, 'preprocessed.pkl')\n",
    "transformed_filepath = os.path.join(backup_dir, 'transformed_data.pkl')\n",
    "\n",
    "# Check if both files exist and load them if they do\n",
    "if not os.path.exists(preprocessed_filepath):\n",
    "    print(f\"File does not exist: {preprocessed_filepath}\")\n",
    "else:\n",
    "    df_preprocessed = pd.read_pickle(preprocessed_filepath)\n",
    "    print(\"Loaded 'preprocessed.pkl' successfully.\")\n",
    "\n",
    "# Save 'transformed_data.pkl' in the same directory\n",
    "# Assuming df_transformed is the DataFrame you want to save\n",
    "# Uncomment the following lines if you have df_transformed ready to save\n",
    "# df_transformed.to_pickle(transformed_filepath)\n",
    "# print(f\"'transformed_data.pkl' saved successfully at {transformed_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80848520-1209-43ad-b859-06baaf9ff989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Directly specify the full path including the date directory\n",
    "data_dir = r\"C:\\Users\\amitniti\\OneDrive - Intel Corporation\\Documents\\AJ-Personal\\(INTEL) IISc-MTech\\2-Data Science in Practice\\Project-1-DSiP-DiabetesReadmit\\ANJ_GITclone\\2024-11-14\\Backup_Dataset\"\n",
    "preprocessed_saved_filepath = os.path.join(data_dir, 'Preprocessed', 'preprocessed.pkl')\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.exists(preprocessed_saved_filepath):\n",
    "    print(f\"File does not exist: {preprocessed_saved_filepath}\")\n",
    "else:\n",
    "    # Load the pickle file\n",
    "    df = pd.read_pickle(preprocessed_saved_filepath)\n",
    "    print(\"Dataframe loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a83635-566a-41af-889c-417c979322de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (69987, 44)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 69987 entries, 0 to 101765\n",
      "Data columns (total 44 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   encounter_id              69987 non-null  int64   \n",
      " 1   patient_nbr               69987 non-null  int64   \n",
      " 2   race                      69987 non-null  category\n",
      " 3   gender                    69987 non-null  object  \n",
      " 4   age                       69987 non-null  object  \n",
      " 5   admission_type_id         69987 non-null  category\n",
      " 6   discharge_disposition_id  69987 non-null  category\n",
      " 7   admission_source_id       69987 non-null  category\n",
      " 8   time_in_hospital          69987 non-null  int64   \n",
      " 9   medical_specialty         69987 non-null  category\n",
      " 10  num_lab_procedures        69987 non-null  int64   \n",
      " 11  num_procedures            69987 non-null  int64   \n",
      " 12  num_medications           69987 non-null  int64   \n",
      " 13  number_outpatient         69987 non-null  int64   \n",
      " 14  number_emergency          69987 non-null  int64   \n",
      " 15  number_inpatient          69987 non-null  int64   \n",
      " 16  diag_1                    69987 non-null  category\n",
      " 17  diag_2                    69987 non-null  category\n",
      " 18  diag_3                    69987 non-null  category\n",
      " 19  number_diagnoses          69987 non-null  int64   \n",
      " 20  max_glu_serum             69987 non-null  int64   \n",
      " 21  A1Cresult                 69987 non-null  int64   \n",
      " 22  metformin                 69987 non-null  int64   \n",
      " 23  repaglinide               69987 non-null  int64   \n",
      " 24  glimepiride               69987 non-null  int64   \n",
      " 25  glipizide                 69987 non-null  int64   \n",
      " 26  glyburide                 69987 non-null  int64   \n",
      " 27  pioglitazone              69987 non-null  int64   \n",
      " 28  rosiglitazone             69987 non-null  int64   \n",
      " 29  insulin                   69987 non-null  int64   \n",
      " 30  change                    69987 non-null  category\n",
      " 31  diabetesMed               69987 non-null  category\n",
      " 32  readmitted                69987 non-null  category\n",
      " 33  age-binned                69987 non-null  category\n",
      " 34  max_glu_serum_measured    69987 non-null  category\n",
      " 35  A1Cresult_measured        69987 non-null  category\n",
      " 36  repaglinide_measured      69987 non-null  category\n",
      " 37  glimepiride_measured      69987 non-null  category\n",
      " 38  rosiglitazone_measured    69987 non-null  category\n",
      " 39  pioglitazone_measured     69987 non-null  category\n",
      " 40  glyburide_measured        69987 non-null  category\n",
      " 41  glipizide_measured        69987 non-null  category\n",
      " 42  metformin_measured        69987 non-null  category\n",
      " 43  insulin_measured          69987 non-null  category\n",
      "dtypes: category(22), int64(20), object(2)\n",
      "memory usage: 13.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \",df.shape) #(69987, 44)\n",
    "print()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baccc4e-7a8f-43e0-8f22-af045aefbd86",
   "metadata": {},
   "source": [
    "### Numerical Column Analysis ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b11b4b8-6a8d-439a-9dc8-d7b33f769d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "  'num_lab_procedures', 'num_medications', 'num_procedures', 'number_diagnoses', 'number_inpatient', 'number_outpatient', 'time_in_hospital'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "988be1d2-45a7-4838-82ba-1d19fe304660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <td>69987.0</td>\n",
       "      <td>42.875863</td>\n",
       "      <td>19.894291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_medications</th>\n",
       "      <td>69987.0</td>\n",
       "      <td>15.665281</td>\n",
       "      <td>8.287321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_procedures</th>\n",
       "      <td>69987.0</td>\n",
       "      <td>1.425379</td>\n",
       "      <td>1.757003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_diagnoses</th>\n",
       "      <td>69987.0</td>\n",
       "      <td>7.224170</td>\n",
       "      <td>2.001257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_inpatient</th>\n",
       "      <td>69987.0</td>\n",
       "      <td>0.176276</td>\n",
       "      <td>0.601633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_outpatient</th>\n",
       "      <td>69987.0</td>\n",
       "      <td>0.279595</td>\n",
       "      <td>1.064108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_in_hospital</th>\n",
       "      <td>69987.0</td>\n",
       "      <td>4.273336</td>\n",
       "      <td>2.933987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count       mean        std  min   25%   50%   75%  \\\n",
       "num_lab_procedures  69987.0  42.875863  19.894291  1.0  31.0  44.0  57.0   \n",
       "num_medications     69987.0  15.665281   8.287321  1.0  10.0  14.0  20.0   \n",
       "num_procedures      69987.0   1.425379   1.757003  0.0   0.0   1.0   2.0   \n",
       "number_diagnoses    69987.0   7.224170   2.001257  1.0   6.0   8.0   9.0   \n",
       "number_inpatient    69987.0   0.176276   0.601633  0.0   0.0   0.0   0.0   \n",
       "number_outpatient   69987.0   0.279595   1.064108  0.0   0.0   0.0   0.0   \n",
       "time_in_hospital    69987.0   4.273336   2.933987  1.0   2.0   3.0   6.0   \n",
       "\n",
       "                      max  \n",
       "num_lab_procedures  132.0  \n",
       "num_medications      81.0  \n",
       "num_procedures        6.0  \n",
       "number_diagnoses     16.0  \n",
       "number_inpatient     12.0  \n",
       "number_outpatient    42.0  \n",
       "time_in_hospital     14.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa78de1-e184-44b5-b00e-75b7dfcaa962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>...</th>\n",
       "      <th>max_glu_serum_measured</th>\n",
       "      <th>A1Cresult_measured</th>\n",
       "      <th>repaglinide_measured</th>\n",
       "      <th>glimepiride_measured</th>\n",
       "      <th>rosiglitazone_measured</th>\n",
       "      <th>pioglitazone_measured</th>\n",
       "      <th>glyburide_measured</th>\n",
       "      <th>glipizide_measured</th>\n",
       "      <th>metformin_measured</th>\n",
       "      <th>insulin_measured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Pediatrics-Endocrinology</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101754</th>\n",
       "      <td>443842016</td>\n",
       "      <td>183087545</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101755</th>\n",
       "      <td>443842022</td>\n",
       "      <td>188574944</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101756</th>\n",
       "      <td>443842070</td>\n",
       "      <td>140199494</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101758</th>\n",
       "      <td>443842340</td>\n",
       "      <td>120975314</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101765</th>\n",
       "      <td>443867222</td>\n",
       "      <td>175429310</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69987 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        encounter_id  patient_nbr             race  gender      age  \\\n",
       "0            2278392      8222157        Caucasian  Female   [0-10)   \n",
       "1             149190     55629189        Caucasian  Female  [10-20)   \n",
       "2              64410     86047875  AfricanAmerican  Female  [20-30)   \n",
       "3             500364     82442376        Caucasian    Male  [30-40)   \n",
       "4              16680     42519267        Caucasian    Male  [40-50)   \n",
       "...              ...          ...              ...     ...      ...   \n",
       "101754     443842016    183087545        Caucasian  Female  [70-80)   \n",
       "101755     443842022    188574944            Other  Female  [40-50)   \n",
       "101756     443842070    140199494            Other  Female  [60-70)   \n",
       "101758     443842340    120975314        Caucasian  Female  [80-90)   \n",
       "101765     443867222    175429310        Caucasian    Male  [70-80)   \n",
       "\n",
       "       admission_type_id discharge_disposition_id admission_source_id  \\\n",
       "0                      6                       25                   1   \n",
       "1                      1                        1                   7   \n",
       "2                      1                        1                   7   \n",
       "3                      1                        1                   7   \n",
       "4                      1                        1                   7   \n",
       "...                  ...                      ...                 ...   \n",
       "101754                 1                        1                   7   \n",
       "101755                 1                        1                   7   \n",
       "101756                 1                        1                   7   \n",
       "101758                 1                        1                   7   \n",
       "101765                 1                        1                   7   \n",
       "\n",
       "        time_in_hospital         medical_specialty  ...  \\\n",
       "0               0.000000  Pediatrics-Endocrinology  ...   \n",
       "1               0.153846                   Unknown  ...   \n",
       "2               0.076923                   Unknown  ...   \n",
       "3               0.076923                   Unknown  ...   \n",
       "4               0.000000                   Unknown  ...   \n",
       "...                  ...                       ...  ...   \n",
       "101754          0.615385                   Unknown  ...   \n",
       "101755          1.000000                   Unknown  ...   \n",
       "101756          0.076923                   Unknown  ...   \n",
       "101758          0.307692                   Unknown  ...   \n",
       "101765          0.384615                   Unknown  ...   \n",
       "\n",
       "        max_glu_serum_measured  A1Cresult_measured  repaglinide_measured  \\\n",
       "0                           No                  No                    No   \n",
       "1                           No                  No                    No   \n",
       "2                           No                  No                    No   \n",
       "3                           No                  No                    No   \n",
       "4                           No                  No                    No   \n",
       "...                        ...                 ...                   ...   \n",
       "101754                      No                 Yes                    No   \n",
       "101755                      No                 Yes                    No   \n",
       "101756                      No                  No                    No   \n",
       "101758                      No                  No                    No   \n",
       "101765                      No                  No                    No   \n",
       "\n",
       "        glimepiride_measured  rosiglitazone_measured  pioglitazone_measured  \\\n",
       "0                         No                      No                     No   \n",
       "1                         No                      No                     No   \n",
       "2                         No                      No                     No   \n",
       "3                         No                      No                     No   \n",
       "4                         No                      No                     No   \n",
       "...                      ...                     ...                    ...   \n",
       "101754                    No                      No                     No   \n",
       "101755                    No                      No                     No   \n",
       "101756                    No                      No                     No   \n",
       "101758                    No                      No                     No   \n",
       "101765                    No                      No                     No   \n",
       "\n",
       "       glyburide_measured glipizide_measured metformin_measured  \\\n",
       "0                      No                 No                 No   \n",
       "1                      No                 No                 No   \n",
       "2                      No                Yes                 No   \n",
       "3                      No                 No                 No   \n",
       "4                      No                Yes                 No   \n",
       "...                   ...                ...                ...   \n",
       "101754                Yes                 No                 No   \n",
       "101755                 No                Yes                 No   \n",
       "101756                 No                 No                 No   \n",
       "101758                 No                 No                 No   \n",
       "101765                 No                 No                 No   \n",
       "\n",
       "        insulin_measured  \n",
       "0                     No  \n",
       "1                    Yes  \n",
       "2                     No  \n",
       "3                    Yes  \n",
       "4                    Yes  \n",
       "...                  ...  \n",
       "101754               Yes  \n",
       "101755               Yes  \n",
       "101756               Yes  \n",
       "101758               Yes  \n",
       "101765                No  \n",
       "\n",
       "[69987 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the numerical columns\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df11a026-2fef-4887-8ca4-0bf3d2d684dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amitniti\\OneDrive - Intel Corporation\\Documents\\AJ-Personal\\(INTEL) IISc-MTech\\2-Data Science in Practice\\Project-1-DSiP-DiabetesReadmit\\ANJ_GITclone\\2024-11-20\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff04fa4-4519-4fdb-b423-5b61711460b5",
   "metadata": {},
   "source": [
    "#### Additional Polynomial Features (Squared and Square Root) #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adb92a04-9800-424e-88c6-996842873bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling and selection with polynomial features completed. Transformed data is ready in 'transformed_data_df'.\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(columns=['readmitted'])  # Assuming 'readmitted' is the target\n",
    "y = df['readmitted']\n",
    "\n",
    "# Encode the target variable if it is categorical\n",
    "if y.dtype == 'object' or isinstance(y.iloc[0], str):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Step 1: Feature Scaling and Polynomial Feature Engineering\n",
    "\n",
    "# Identify numerical columns for scaling and polynomial features\n",
    "numerical_cols = [\n",
    "    'num_lab_procedures', 'num_medications', 'num_procedures',\n",
    "    'number_diagnoses', 'number_inpatient', 'number_outpatient', 'time_in_hospital'\n",
    "]\n",
    "\n",
    "# Handle missing values in numerical columns\n",
    "X[numerical_cols] = X[numerical_cols].fillna(X[numerical_cols].median())\n",
    "\n",
    "# Generate Polynomial Features (Squared and Square Root)\n",
    "for col in numerical_cols:\n",
    "    X[f'{col}_squared'] = X[col] ** 2\n",
    "    X[f'{col}_sqrt'] = np.sqrt(X[col].clip(lower=0))  # Replace negatives with 0\n",
    "\n",
    "# Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "features_to_scale = numerical_cols + [f'{col}_squared' for col in numerical_cols] + [f'{col}_sqrt' for col in numerical_cols]\n",
    "X[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n",
    "\n",
    "# Step 2: One-Hot Encoding for Categorical Features\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Step 3: Feature Selection\n",
    "\n",
    "# (a) Remove Highly Correlated Features\n",
    "correlation_matrix = X.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "high_corr_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
    "X = X.drop(columns=high_corr_features)\n",
    "\n",
    "# (b) Feature Importance using RandomForestClassifier\n",
    "# Split data for feature importance calculation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit a Random Forest model to get feature importances\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf_model.feature_importances_, index=X.columns, columns=['Importance']\n",
    ").sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select top k features based on importance (e.g., k=20)\n",
    "k = 20\n",
    "top_features = feature_importances.head(k).index\n",
    "X = X[top_features]\n",
    "\n",
    "# Step 4: Create In-Memory Transformed DataFrame\n",
    "transformed_data_df = pd.concat([X, pd.Series(y, name='readmitted')], axis=1)\n",
    "\n",
    "print(\"Feature scaling and selection with polynomial features completed. Transformed data is ready in 'transformed_data_df'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a9df6a8-4466-44bf-84e8-887a577070c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (89319, 21)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 89319 entries, 0 to 69985\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   encounter_id               69987 non-null  float64\n",
      " 1   patient_nbr                69987 non-null  float64\n",
      " 2   num_lab_procedures         69987 non-null  float64\n",
      " 3   num_medications            69987 non-null  float64\n",
      " 4   time_in_hospital           69987 non-null  float64\n",
      " 5   number_diagnoses           69987 non-null  float64\n",
      " 6   num_procedures             69987 non-null  float64\n",
      " 7   insulin                    69987 non-null  float64\n",
      " 8   gender_Male                69987 non-null  object \n",
      " 9   A1Cresult                  69987 non-null  float64\n",
      " 10  diag_2_Other               69987 non-null  object \n",
      " 11  diag_3_Other               69987 non-null  object \n",
      " 12  number_inpatient_squared   69987 non-null  float64\n",
      " 13  metformin                  69987 non-null  float64\n",
      " 14  diag_1_Other               69987 non-null  object \n",
      " 15  medical_specialty_Unknown  69987 non-null  object \n",
      " 16  race_Caucasian             69987 non-null  object \n",
      " 17  change_No                  69987 non-null  object \n",
      " 18  age_[60-70)                69987 non-null  object \n",
      " 19  number_inpatient           69987 non-null  float64\n",
      " 20  readmitted                 69987 non-null  float64\n",
      "dtypes: float64(13), object(8)\n",
      "memory usage: 15.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", transformed_data_df.shape)\n",
    "print()\n",
    "\n",
    "print(transformed_data_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c67b7c68-1ff0-439e-937d-482c64ff2161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>insulin</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_3_Other</th>\n",
       "      <th>number_inpatient_squared</th>\n",
       "      <th>metformin</th>\n",
       "      <th>diag_1_Other</th>\n",
       "      <th>medical_specialty_Unknown</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>change_No</th>\n",
       "      <th>age_[60-70)</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392.0</td>\n",
       "      <td>8222157.0</td>\n",
       "      <td>-0.094292</td>\n",
       "      <td>-1.769617</td>\n",
       "      <td>-1.115670</td>\n",
       "      <td>-3.110153</td>\n",
       "      <td>-0.811261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.144824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.292997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190.0</td>\n",
       "      <td>55629189.0</td>\n",
       "      <td>0.810496</td>\n",
       "      <td>0.281724</td>\n",
       "      <td>-0.433998</td>\n",
       "      <td>0.887364</td>\n",
       "      <td>-0.811261</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.144824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.292997</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410.0</td>\n",
       "      <td>86047875.0</td>\n",
       "      <td>-1.602273</td>\n",
       "      <td>-0.321612</td>\n",
       "      <td>-0.774834</td>\n",
       "      <td>-0.611705</td>\n",
       "      <td>2.034513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.223657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.369158</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364.0</td>\n",
       "      <td>82442376.0</td>\n",
       "      <td>0.056506</td>\n",
       "      <td>0.040390</td>\n",
       "      <td>-0.774834</td>\n",
       "      <td>-0.112016</td>\n",
       "      <td>-0.242107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.144824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.292997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680.0</td>\n",
       "      <td>42519267.0</td>\n",
       "      <td>0.408368</td>\n",
       "      <td>-0.924947</td>\n",
       "      <td>-1.115670</td>\n",
       "      <td>-1.111395</td>\n",
       "      <td>-0.811261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.144824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.292997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69968</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69970</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69978</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69983</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89319 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       encounter_id  patient_nbr  num_lab_procedures  num_medications  \\\n",
       "0         2278392.0    8222157.0           -0.094292        -1.769617   \n",
       "1          149190.0   55629189.0            0.810496         0.281724   \n",
       "2           64410.0   86047875.0           -1.602273        -0.321612   \n",
       "3          500364.0   82442376.0            0.056506         0.040390   \n",
       "4           16680.0   42519267.0            0.408368        -0.924947   \n",
       "...             ...          ...                 ...              ...   \n",
       "69968           NaN          NaN                 NaN              NaN   \n",
       "69970           NaN          NaN                 NaN              NaN   \n",
       "69978           NaN          NaN                 NaN              NaN   \n",
       "69983           NaN          NaN                 NaN              NaN   \n",
       "69985           NaN          NaN                 NaN              NaN   \n",
       "\n",
       "       time_in_hospital  number_diagnoses  num_procedures  insulin  \\\n",
       "0             -1.115670         -3.110153       -0.811261      0.0   \n",
       "1             -0.433998          0.887364       -0.811261      2.0   \n",
       "2             -0.774834         -0.611705        2.034513      0.0   \n",
       "3             -0.774834         -0.112016       -0.242107      2.0   \n",
       "4             -1.115670         -1.111395       -0.811261      1.0   \n",
       "...                 ...               ...             ...      ...   \n",
       "69968               NaN               NaN             NaN      NaN   \n",
       "69970               NaN               NaN             NaN      NaN   \n",
       "69978               NaN               NaN             NaN      NaN   \n",
       "69983               NaN               NaN             NaN      NaN   \n",
       "69985               NaN               NaN             NaN      NaN   \n",
       "\n",
       "      gender_Male  A1Cresult  ... diag_3_Other number_inpatient_squared  \\\n",
       "0           False        0.0  ...        False                -0.144824   \n",
       "1           False        0.0  ...         True                -0.144824   \n",
       "2           False        0.0  ...         True                 0.223657   \n",
       "3            True        0.0  ...        False                -0.144824   \n",
       "4            True        0.0  ...        False                -0.144824   \n",
       "...           ...        ...  ...          ...                      ...   \n",
       "69968         NaN        NaN  ...          NaN                      NaN   \n",
       "69970         NaN        NaN  ...          NaN                      NaN   \n",
       "69978         NaN        NaN  ...          NaN                      NaN   \n",
       "69983         NaN        NaN  ...          NaN                      NaN   \n",
       "69985         NaN        NaN  ...          NaN                      NaN   \n",
       "\n",
       "       metformin  diag_1_Other medical_specialty_Unknown race_Caucasian  \\\n",
       "0            0.0          True                     False           True   \n",
       "1            0.0          True                      True           True   \n",
       "2            0.0          True                      True          False   \n",
       "3            0.0          True                      True           True   \n",
       "4            0.0         False                      True           True   \n",
       "...          ...           ...                       ...            ...   \n",
       "69968        NaN           NaN                       NaN            NaN   \n",
       "69970        NaN           NaN                       NaN            NaN   \n",
       "69978        NaN           NaN                       NaN            NaN   \n",
       "69983        NaN           NaN                       NaN            NaN   \n",
       "69985        NaN           NaN                       NaN            NaN   \n",
       "\n",
       "      change_No age_[60-70) number_inpatient  readmitted  \n",
       "0          True       False        -0.292997         0.0  \n",
       "1         False       False        -0.292997         1.0  \n",
       "2          True       False         1.369158         0.0  \n",
       "3         False       False        -0.292997         0.0  \n",
       "4         False       False        -0.292997         0.0  \n",
       "...         ...         ...              ...         ...  \n",
       "69968       NaN         NaN              NaN         0.0  \n",
       "69970       NaN         NaN              NaN         0.0  \n",
       "69978       NaN         NaN              NaN         0.0  \n",
       "69983       NaN         NaN              NaN         1.0  \n",
       "69985       NaN         NaN              NaN         0.0  \n",
       "\n",
       "[89319 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e464c-08d9-46ff-afe3-9b6020c43202",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center; color: #2E8B57;\"><b>Data Preparation and Feature Engineering Process</b></h2>\n",
    "\n",
    "<p style=\"color: #006400; font-size: 1.1em;\">This process outlines the steps undertaken for preprocessing, feature scaling, encoding, and selection to prepare the dataset for machine learning tasks.</p>\n",
    "\n",
    "<hr style=\"border: 1px solid #2E8B57;\">\n",
    "\n",
    "<h3 style=\"color: #2E8B57;\">1. 📚 Import Necessary Libraries</h3>\n",
    "<ul style=\"color: #006400; font-size: 1.05em; list-style: none; padding-left: 0;\">\n",
    "    <li>🔹 Essential Python libraries such as <b>pandas</b>, <b>numpy</b>, and <b>sklearn</b> are imported for:</li>\n",
    "    <ul style=\"color: #006400; font-size: 1em;\">\n",
    "        <li>Data preprocessing</li>\n",
    "        <li>Scaling</li>\n",
    "        <li>Feature selection</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"color: #2E8B57;\">2. 🗃️ Load Preprocessed Data</h3>\n",
    "<ul style=\"color: #006400; font-size: 1.05em; list-style: none; padding-left: 0;\">\n",
    "    <li>🔸 The preprocessed data is loaded from <b>preprocessed.pkl</b>, which contains a cleaned and structured dataset.</li>\n",
    "    <li>🔸 The dataset is split into features (<b>X</b>) and the target variable (<b>y</b>).</li>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"color: #2E8B57;\">3. 🔄 Encoding the Target Variable</h3>\n",
    "<ul style=\"color: #006400; font-size: 1.05em; list-style: none; padding-left: 0;\">\n",
    "    <li>🔹 If the target variable (<b>readmitted</b>) contains non-numeric labels, they are encoded into numeric values using <b>LabelEncoder</b>.</li>\n",
    "    <li>🔹 This step is essential as most machine learning algorithms require numeric inputs.</li>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"color: #2E8B57;\">4. 📏 Feature Scaling</h3>\n",
    "<ul style=\"color: #006400; font-size: 1.05em; list-style: none; padding-left: 0;\">\n",
    "    <li>🔸 <b>Numerical Columns Identification:</b> Identifies numerical columns in <b>X</b> using <code>select_dtypes(include=[np.number])</code>.</li>\n",
    "    <li>🔸 <b>Standard Scaling:</b> Applies <b>StandardScaler</b> to ensure numerical data has a mean of 0 and standard deviation of 1.</li>\n",
    "    <li>🔸 <b>Importance of Scaling:</b></li>\n",
    "    <ul style=\"color: #006400; font-size: 1em;\">\n",
    "        <li>Ensures features are on the same scale.</li>\n",
    "        <li>Prevents features with larger magnitudes from dominating the model's learning process.</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"color: #2E8B57;\">5. 🔧 One-Hot Encoding for Categorical Features</h3>\n",
    "<ul style=\"color: #006400; font-size: 1.05em; list-style: none; padding-left: 0;\">\n",
    "    <li>🔹 Converts categorical columns into numerical format using <code>pd.get_dummies</code>.</li>\n",
    "    <li>🔹 Represents each category as a binary feature, ensuring compatibility with machine learning algorithms.</li>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"color: #2E8B57;\">6. 🎯 Feature Selection</h3>\n",
    "<ul style=\"color: #006400; font-size: 1.05em; list-style: none; padding-left: 0;\">\n",
    "    <li>🔸 <b>Highly Correlated Features:</b></li>\n",
    "    <ul style=\"color: #006400; font-size: 1em;\">\n",
    "        <li>Calculates a correlation matrix for numerical columns.</li>\n",
    "        <li>Removes features with a high correlation (>0.9) to reduce multicollinearity.</li>\n",
    "    </ul>\n",
    "    <li>🔸 <b>Feature Importance via Random Forest:</b> Retains the top <b>k</b> features (e.g., <b>k=20</b>) based on feature importance scores.</li>\n",
    "    <li>🔸 <b>Chi-Square Test for Categorical Features:</b> Evaluates independence between categorical features and the target variable to select the most relevant ones.</li>\n",
    "</ul>\n",
    "\n",
    "<h3 style=\"color: #2E8B57;\">7. 💾 Save Transformed Dataset</h3>\n",
    "<ul style=\"color: #006400; font-size: 1.05em; list-style: none; padding-left: 0;\">\n",
    "    <li>🔹 The final transformed dataset (features + target) is saved to <b>transformed_data.pkl</b> for downstream tasks.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"color: #006400; font-size: 1.1em;\"><b>Conclusion:</b> These steps ensure that the dataset is ready for modeling by handling categorical variables, scaling numerical features, and selecting the most impactful features. This process establishes a robust foundation for building accurate predictive models.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acdc5f-b814-4825-afde-334d98e4d9ec",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: blue;\"><b>Model Training and Evaluation</b></h1>\n",
    "<h2 style=\"text-align: center; color: blue;\"><b>Random Forest Classifier for Readmission Prediction</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50a0f868-dbe5-4e82-a07c-c5f1cf018bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.dtypes\n",
      " encounter_id                   int64\n",
      "patient_nbr                    int64\n",
      "num_lab_procedures           float64\n",
      "num_medications              float64\n",
      "time_in_hospital             float64\n",
      "number_diagnoses             float64\n",
      "num_procedures               float64\n",
      "insulin                        int64\n",
      "gender_Male                     bool\n",
      "A1Cresult                      int64\n",
      "diag_2_Other                    bool\n",
      "diag_3_Other                    bool\n",
      "number_inpatient_squared     float64\n",
      "metformin                      int64\n",
      "diag_1_Other                    bool\n",
      "medical_specialty_Unknown       bool\n",
      "race_Caucasian                  bool\n",
      "change_No                       bool\n",
      "age_[60-70)                     bool\n",
      "number_inpatient             float64\n",
      "dtype: object\n",
      "\n",
      "y.dtype\n",
      " int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"X.dtypes\\n\",X.dtypes)\n",
    "print()\n",
    "print(f\"y.dtype\\n\",y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a71a5d1-3897-476e-a1e6-1f96c5a6e8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.isnull()\n",
      " encounter_id                 0\n",
      "patient_nbr                  0\n",
      "num_lab_procedures           0\n",
      "num_medications              0\n",
      "time_in_hospital             0\n",
      "number_diagnoses             0\n",
      "num_procedures               0\n",
      "insulin                      0\n",
      "gender_Male                  0\n",
      "A1Cresult                    0\n",
      "diag_2_Other                 0\n",
      "diag_3_Other                 0\n",
      "number_inpatient_squared     0\n",
      "metformin                    0\n",
      "diag_1_Other                 0\n",
      "medical_specialty_Unknown    0\n",
      "race_Caucasian               0\n",
      "change_No                    0\n",
      "age_[60-70)                  0\n",
      "number_inpatient             0\n",
      "dtype: int64\n",
      "\n",
      "y.isnull()\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"X.isnull()\\n\", X.isnull().sum())\n",
    "print()\n",
    "# Check for null values in y (NumPy array)\n",
    "print(f\"y.isnull()\\n\", np.isnan(y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb8bec0c-78ac-4e36-acdd-77973cbbd831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set: Used for evaluating the model's performance\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = transformed_data_df.drop(columns=['readmitted'])\n",
    "y = transformed_data_df['readmitted']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print a message indicating the purpose of the testing set\n",
    "print(\"Testing set: Used for evaluating the model's performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e408677-d643-4b79-a9d2-c77ee258cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in y: 19332\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in y\n",
    "print(\"Missing values in y:\", y.isnull().sum())\n",
    "\n",
    "# Drop rows with NaN in y\n",
    "valid_indices = y.dropna().index\n",
    "X = X.loc[valid_indices]\n",
    "y = y.loc[valid_indices]\n",
    "\n",
    "# Now split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40470cb-3e42-40a1-89ac-73491d982612",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: blue;\"><b>Model Training and Evaluation</b></h1>\n",
    "<h2 style=\"text-align: center; color: blue;\"><b>Plain Decision/Binary Tree  for Readmission Prediction</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cd87011-4bd9-4726-9f5f-81ead1952834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in y: 19332\n",
      "Accuracy: 0.5923227127684907\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.89      0.72     12455\n",
      "         1.0       0.50      0.17      0.25      8542\n",
      "\n",
      "    accuracy                           0.59     20997\n",
      "   macro avg       0.55      0.53      0.48     20997\n",
      "weighted avg       0.56      0.59      0.53     20997\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[11023  1432]\n",
      " [ 7128  1414]]\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = transformed_data_df.drop(columns=['readmitted'])  # assuming 'readmitted' is the target variable\n",
    "y = transformed_data_df['readmitted']\n",
    "\n",
    "# Check for NaN values in y and remove them\n",
    "print(\"Missing values in y:\", y.isnull().sum())\n",
    "valid_indices = y.dropna().index\n",
    "X = X.loc[valid_indices]\n",
    "y = y.loc[valid_indices]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train a Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier(random_state=42, max_depth=5)  # Adjust max_depth to control overfitting\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ed31318-fa56-4824-94b3-11fb3489264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Accuracy: 0.558948806557904\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.75      0.63     12468\n",
      "         1.0       0.59      0.37      0.46     12418\n",
      "\n",
      "    accuracy                           0.56     24886\n",
      "   macro avg       0.57      0.56      0.54     24886\n",
      "weighted avg       0.57      0.56      0.54     24886\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9291 3177]\n",
      " [7799 4619]]\n"
     ]
    }
   ],
   "source": [
    "# Select only relevant numeric features\n",
    "numeric_features = [\n",
    "    'num_lab_procedures', 'num_medications', 'time_in_hospital',\n",
    "    'number_diagnoses', 'num_procedures', 'number_inpatient'\n",
    "]\n",
    "X = transformed_data_df[numeric_features]\n",
    "y = transformed_data_df['readmitted']\n",
    "\n",
    "# Handle NaN values in X and y together\n",
    "X = X.fillna(X.median())\n",
    "valid_indices = y.dropna().index  # Drop NaN values from y and align with X\n",
    "X = X.loc[valid_indices]\n",
    "y = y.loc[valid_indices]\n",
    "\n",
    "# Ensure X and y have the same number of samples\n",
    "assert len(X) == len(y), \"X and y have inconsistent lengths!\"\n",
    "\n",
    "# Balance classes using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Perform hyperparameter tuning and training\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42, class_weight='balanced'), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "add8a53b-4f7a-44dd-92a7-44830ac4a584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in y: 19332\n",
      "Missing values in X before imputation: 386640\n",
      "Missing values in X after imputation: 0\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\n",
      "Decision Tree Model (After Improvements)\n",
      "Accuracy: 0.5883629349835249\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.86      0.68     12468\n",
      "         1.0       0.70      0.31      0.43     12418\n",
      "\n",
      "    accuracy                           0.59     24886\n",
      "   macro avg       0.63      0.59      0.55     24886\n",
      "weighted avg       0.63      0.59      0.55     24886\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10770  1698]\n",
      " [ 8546  3872]]\n",
      "\n",
      "Top Features Contributing to the Model:\n",
      "                Feature  Importance\n",
      "10        diag_2_Other    0.306597\n",
      "8          gender_Male    0.223302\n",
      "0         encounter_id    0.155998\n",
      "11        diag_3_Other    0.059870\n",
      "7              insulin    0.035942\n",
      "1          patient_nbr    0.034678\n",
      "2   num_lab_procedures    0.030891\n",
      "5     number_diagnoses    0.025276\n",
      "6       num_procedures    0.023118\n",
      "13           metformin    0.016958\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate features and target variable\n",
    "X = transformed_data_df.drop(columns=['readmitted'])  # assuming 'readmitted' is the target variable\n",
    "y = transformed_data_df['readmitted']\n",
    "\n",
    "# Check for NaN values in y and remove them\n",
    "print(\"Missing values in y:\", y.isnull().sum())\n",
    "valid_indices = y.dropna().index\n",
    "X = X.loc[valid_indices]\n",
    "y = y.loc[valid_indices]\n",
    "\n",
    "# Handle missing values in X if any\n",
    "print(\"Missing values in X before imputation:\", X.isnull().sum().sum())\n",
    "X.fillna(X.median(), inplace=True)  # Replace NaN with median for numerical columns\n",
    "print(\"Missing values in X after imputation:\", X.isnull().sum().sum())\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter Tuning with Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_decision_tree = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model\n",
    "best_decision_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_decision_tree.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nDecision Tree Model (After Improvements)\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Feature Importance Analysis\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_decision_tree.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop Features Contributing to the Model:\\n\", feature_importances.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311eb084-e67f-4675-a86d-6f66e61eeb49",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: #1E90FF;\"><b>Insights on Decision Tree Results</b></h1>\n",
    "<hr style=\"border: 2px solid #4682B4;\">\n",
    "\n",
    "<h2 style=\"color: #4682B4;\">📊 <b>Model Performance (Decision Tree After Improvements)</b></h2>\n",
    "<ul style=\"color: #4B0082; font-size: 1.1em;\">\n",
    "    <li><b>Accuracy:</b> 0.59 - The model correctly classifies 59% of cases, showing moderate improvement.</li>\n",
    "    <li><b>Precision:</b>\n",
    "        <ul>\n",
    "            <li><b>Class 0 (Not Readmitted):</b> 0.56 - 56% of predicted non-readmissions are correct.</li>\n",
    "            <li><b>Class 1 (Readmitted):</b> 0.70 - 70% of predicted readmissions are correct, a significant improvement.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Recall:</b>\n",
    "        <ul>\n",
    "            <li><b>Class 0 (Not Readmitted):</b> 0.86 - High recall indicates the model effectively identifies non-readmitted patients.</li>\n",
    "            <li><b>Class 1 (Readmitted):</b> 0.31 - Low recall means many readmitted patients are missed.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>F1-Score:</b>\n",
    "        <ul>\n",
    "            <li><b>Class 0:</b> 0.68 - Balanced performance for the majority class.</li>\n",
    "            <li><b>Class 1:</b> 0.43 - Shows room for improvement in handling the minority class.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border: 1px dashed #4682B4;\">\n",
    "\n",
    "<h2 style=\"color: #4682B4;\">📋 <b>Confusion Matrix</b></h2>\n",
    "<ul style=\"color: #4B0082; font-size: 1.1em;\">\n",
    "    <li><b>True Positives (TP):</b> 3872 - Correctly predicted readmitted cases.</li>\n",
    "    <li><b>False Negatives (FN):</b> 8546 - Readmitted cases missed by the model.</li>\n",
    "    <li><b>True Negatives (TN):</b> 10770 - Correctly predicted non-readmitted cases.</li>\n",
    "    <li><b>False Positives (FP):</b> 1698 - Non-readmitted cases predicted as readmitted.</li>\n",
    "</ul>\n",
    "<p style=\"color: #4B0082; font-size: 1.1em;\">The high number of <b>False Negatives (8,546)</b> highlights the need to improve recall for readmitted patients.</p>\n",
    "\n",
    "<hr style=\"border: 1px dashed #4682B4;\">\n",
    "\n",
    "<h2 style=\"color: #4682B4;\">📈 <b>Feature Importance Analysis</b></h2>\n",
    "<ul style=\"color: #4B0082; font-size: 1.1em;\">\n",
    "    <li><b>Top Features:</b></li>\n",
    "    <ul>\n",
    "        <li><b>diag_2_Other:</b> 0.3066 - Most significant feature, reflecting the role of diagnosis codes.</li>\n",
    "        <li><b>gender_Male:</b> 0.2233 - Gender plays a key role, particularly male patients.</li>\n",
    "        <li><b>encounter_id:</b> 0.1560 - Requires investigation to ensure no data leakage.</li>\n",
    "        <li><b>diag_3_Other:</b> 0.0599 - Another diagnosis-related feature.</li>\n",
    "        <li><b>insulin:</b> 0.0359 - Reflects the role of diabetes management.</li>\n",
    "        <li><b>num_lab_procedures:</b> 0.0309 - Key indicator of health evaluations.</li>\n",
    "        <li><b>number_diagnoses:</b> 0.0253 - Patients with multiple diagnoses are at higher risk of readmission.</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border: 1px dashed #4682B4;\">\n",
    "\n",
    "<h2 style=\"color: #4682B4;\">🔍 <b>Key Observations</b></h2>\n",
    "<ul style=\"color: #4B0082; font-size: 1.1em;\">\n",
    "    <li>📉 <b>Class Imbalance:</b> Precision for readmissions improved, but recall remains low, highlighting the imbalance challenge.</li>\n",
    "    <li>🔑 <b>Feature Contributions:</b> Diagnosis codes and gender are the most influential, with patient and encounter attributes requiring validation for potential bias.</li>\n",
    "    <li>🚨 <b>Room for Improvement:</b> Recall for readmitted patients needs further enhancement.</li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border: 1px dashed #4682B4;\">\n",
    "\n",
    "<h2 style=\"color: #4682B4;\">💡 <b>Recommendations</b></h2>\n",
    "<ul style=\"color: #4B0082; font-size: 1.1em;\">\n",
    "    <li>📊 <b>Improve Recall:</b>\n",
    "        <ul>\n",
    "            <li>Implement ensemble models like <b>Random Forest</b> or <b>Gradient Boosting</b>.</li>\n",
    "            <li>Use techniques like <b>Cost-Sensitive Learning</b> or advanced resampling (e.g., <b>ADASYN</b>).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>🔧 <b>Refine Features:</b> Engineer new features (e.g., interaction terms, aggregate metrics).</li>\n",
    "    <li>🔄 <b>Tune Hyperparameters:</b> Optimize tree depth, splits, and explore broader hyperparameter ranges.</li>\n",
    "    <li>🚀 <b>Evaluate Alternate Metrics:</b> Use <b>ROC-AUC</b> to better balance precision and recall trade-offs.</li>\n",
    "</ul>\n",
    "<p style=\"color: #4B0082; font-size: 1.1em;\"><b>Conclusion:</b> While the Decision Tree shows moderate improvement, addressing class imbalance and leveraging advanced models can significantly enhance its predictive power for readmitted patients.</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
