{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa7b6bb-0250-4b95-9409-b7a1716c8ae4",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <style>\n",
    "        body {\n",
    "            background-color: #121212;\n",
    "            color: #E0E0E0;\n",
    "            font-family: Arial, sans-serif;\n",
    "        }\n",
    "        h1, h2, h3 {\n",
    "            color: #BB86FC;\n",
    "            text-align: center;\n",
    "        }\n",
    "        hr {\n",
    "            border: 1px solid #03DAC5;\n",
    "        }\n",
    "        ul {\n",
    "            list-style: none;\n",
    "            padding: 0;\n",
    "        }\n",
    "        ul li::before {\n",
    "            content: \"‚Ä¢\";\n",
    "            color: #BB86FC;\n",
    "            font-weight: bold;\n",
    "            display: inline-block;\n",
    "            width: 1em;\n",
    "            margin-left: -1em;\n",
    "        }\n",
    "        ul ul li::before {\n",
    "            content: \"‚Üí\";\n",
    "            color: #03DAC5;\n",
    "        }\n",
    "        p, ul {\n",
    "            font-size: 1.1em;\n",
    "        }\n",
    "        code {\n",
    "            background-color: #1F1F1F;\n",
    "            color: #BB86FC;\n",
    "            padding: 2px 4px;\n",
    "            border-radius: 4px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1><b><center>Summary of Model Trainings and Quick Insights</center></b></h1>\n",
    "    <hr>\n",
    "    <h2>üîç <b>Model Performances</b></h2>\n",
    "    <h3>1. Logistic Regression</h3>\n",
    "    <ul>\n",
    "        <li><b>Accuracy:</b> 62%</li>\n",
    "        <li><b>Precision:</b> 0.61 (macro avg)</li>\n",
    "        <li><b>Recall:</b> 0.55 (macro avg)</li>\n",
    "        <li><b>F1-Score:</b> 0.56 (weighted avg)</li>\n",
    "        <li><b>Observations:</b>\n",
    "            <ul>\n",
    "                <li>Achieved a high recall for the \"No\" class but struggled with the \"Yes\" class, reflecting class imbalance issues.</li>\n",
    "                <li>Fast training due to simplicity but limited in handling complex datasets due to its linear nature.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <h3>2. XGBoost</h3>\n",
    "    <ul>\n",
    "        <li><b>Accuracy:</b> 64%</li>\n",
    "        <li><b>Precision:</b> 0.59</li>\n",
    "        <li><b>Recall:</b> 0.36</li>\n",
    "        <li><b>F1-Score:</b> 0.45</li>\n",
    "        <li><b>Observations:</b>\n",
    "            <ul>\n",
    "                <li>Slightly improved accuracy compared to Logistic Regression.</li>\n",
    "                <li>Low recall indicates underperformance on certain classes despite hyperparameter tuning.</li>\n",
    "                <li>Requires further experimentation with hyperparameters and feature scaling to maximize performance.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <h3>3. Decision Tree</h3>\n",
    "    <ul>\n",
    "        <li><b>Accuracy:</b> 58.8%</li>\n",
    "        <li><b>Precision:</b> 0.63 (macro avg)</li>\n",
    "        <li><b>Recall:</b> 0.59 (macro avg)</li>\n",
    "        <li><b>F1-Score:</b> 0.55 (weighted avg)</li>\n",
    "        <li><b>Top Features:</b>\n",
    "            <ul>\n",
    "                <li>diag_2_Other</li>\n",
    "                <li>gender_Male</li>\n",
    "                <li>encounter_id</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><b>Observations:</b>\n",
    "            <ul>\n",
    "                <li>Lower accuracy compared to Logistic Regression and XGBoost.</li>\n",
    "                <li>Highly interpretable, with clear feature importance insights.</li>\n",
    "                <li>Prone to overfitting, particularly with deeper trees.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <hr>\n",
    "    <h2>üöÄ <b>Next Steps to Increase Model Accuracy</b></h2>\n",
    "    <ul>\n",
    "        <li>üìä <b>Feature Engineering:</b>\n",
    "            <ul>\n",
    "                <li>Scale numerical features using StandardScaler or MinMaxScaler.</li>\n",
    "                <li>Apply one-hot encoding or other transformations to categorical variables.</li>\n",
    "                <li>Perform feature selection or elimination based on correlation and importance.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>üìâ <b>Class Imbalance Handling:</b>\n",
    "            <ul>\n",
    "                <li>We tried SMOTE. ADASYN or class-weight adjustments can be tried to improve minority class recall further.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>üõ†Ô∏è <b>Data Augmentation:</b>\n",
    "            <ul>\n",
    "                <li>Introduce synthetic data or transformations to improve generalization.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>üîÑ <b>Cross-Validation:</b>\n",
    "            <ul>\n",
    "                <li>Apply stratified K-Fold cross-validation for robust performance evaluation.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>‚ú® <b>Advanced Models:</b>\n",
    "            <ul>\n",
    "                <li>We can next try Neural Networks as the relationship of these features seems complex.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <hr>\n",
    "    <h2>üìã <b>Summary of Model Performances</b></h2>\n",
    "    <ul>\n",
    "        <li>üìâ <b>Logistic Regression:</b> Consistent performance but limited by its linear assumptions.</li>\n",
    "        <li>üåü <b>XGBoost:</b> Best accuracy but struggles with recall. Promising with further tuning.</li>\n",
    "        <li>üå≤ <b>Decision Tree:</b> Interpretability shines, but accuracy lags due to overfitting risks.</li>\n",
    "    </ul>\n",
    "    <hr>\n",
    "    <h2>üí° <b>Conclusion</b></h2>\n",
    "    <p>\n",
    "        The next phase will focus on enhancing <b>feature engineering</b>, balancing class distributions, and optimizing model parameters. Leveraging advanced models there is still little scope to improve accuracy, recall, and F1-score, particularly for the minority class (readmitted patients). This iterative process will refine the predictions and contribute to more reliable outcomes.\n",
    "    </p>\n",
    "</body>\n",
    "</html>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
